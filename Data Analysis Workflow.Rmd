---
title: "Data Analysis Workflow"
---
# 0. Step 0 Get ready
## 0.1 Set working directory
```{r}
getwd()
setwd()
```
**Relative** - `setwd("./data")`, `setwd("../")` (Move up one directory)  
**Absolute** - `setwd("/Users/jtleek/data/")` "/" for path in windows
## 0.2 Check for and create directories
```{r}
# check to see if the directory exists
file.exists("directoryName") 
# create a directory if it doesn't exist
dir.create("directoryName") 

# an example checking for a "data" directory and creating it if it doesn't exist
if(!file.exists("data")){
  dir.create("data")
}
```
# Packages and Tips
## {base}
rewrite the names of the columns to remove any spaces
```{r}
names(ozone) <- make.names(names(ozone))
```
## {ggplot2}
I’ve coloured the models by `-dist`: this is an easy way to make sure that the best models (i.e. the ones with the smallest distance) get the brighest colours.
```{r}
ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, colour = "grey30") + 
  geom_abline(
    aes(intercept = a1, slope = a2, colour = -dist), 
    data = filter(models, rank(dist) <= 10)
  )
```
## {data.table}
Much, much faster at subsetting, group, and updating
### Create data tables just like data frames
```{r}
library(data.table)
DF = data.frame(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
head(DF,3)
DT = data.table(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
head(DT,3)
```
### See all the data tables in memory
```{r}
tables()
```
### Subset rows
```{r}
DT[2,]
DT[DT$y=="a",]
```
### Subsetting is based on rows (not columns like DF[c(2,3)])
```{r}
DT[c(2,3)]
```
**Data table use expression after comma**
### Calculate values for variables with expressions
```{r}
DT[,list(mean(x),sum(z))]
DT[,table(y)]
```
### Add new columns
```{r}
DT[,w:=z^2]
```
**When add a new variable to a data table, a new copy isn't being created.  If you're trying to create a copy, you have to explicitly do that with the copy function.** 
### Multiple operations
```{r}
DT[,m:= {tmp <- (x+z); log2(tmp+5)}]
```
### plyr like operations
```{r}
DT[,a:=x>0]
```

```{r}
DT[,b:= mean(x+w),by=a]
```
`by=a` aggregated/grouped by a. Then add aggregated values (mean in this case) of different groups to each row of b.
### Special variables
`.N` An integer, length 1, containing the number of elements (counts) of a factor level
```{r}
set.seed(123);
DT <- data.table(x=sample(letters[1:3], 1E5, TRUE))
DT[, .N, by=x]
```
### Keys
#### To subset
```{r}
DT <- data.table(x=rep(c("a","b","c"),each=100), y=rnorm(300))
setkey(DT, x)
DT['a']
```
#### To Join(merge)
```{r}
DT1 <- data.table(x=c('a', 'a', 'b', 'dt1'), y=1:4)
DT2 <- data.table(x=c('a', 'b', 'dt2'), z=5:7)
setkey(DT1, x); setkey(DT2, x)
merge(DT1, DT2)
```
### Fast reading from disk
```{r}
big_df <- data.frame(x=rnorm(1E6), y=rnorm(1E6))
file <- tempfile()
write.table(big_df, file=file, row.names=FALSE, col.names=TRUE, sep="\t", quote=FALSE)
system.time(fread(file))
system.time(read.table(file, header=TRUE, sep="\t"))
```
`fread()` could be applied to reading data tables, a substitute for `read.table()` with tab separated files
### Further resources
- [Latest development of data.table](https://github.com/Rdatatable/data.table/wiki)
- [A list of differences between data.table and data.frame](https://stackoverflow.com/questions/13618488/what-you-can-do-with-data-frame-that-you-cant-in-data-table)
## {sqldf}
sqldf package allows for execution of SQL commands on R data frames

# 1. Step 1 Get the data
## 1.1 From the internet
```{r}
# Download the file
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/cameras.csv",mode = 'wb')

# Check the downloaded file
list.files("./data")
# Record the date downloaded
dateDownloaded <- date()
dateDownloaded
```
## 1.2 From local flat files
### 1.2.1 {base}
#### read.table()
```{r}
cameraData <- read.table("./data/cameras.csv",sep=",",header=TRUE)
```
Important parameters
- `file`
- `header`
- `sep` - delimiter
- `row.names`
- `nrows` - how many rows to read of the file (e.g. nrows=10 reads 10 lines)
- `quote` - whether there are any quoted values, quote="" means no quotes
- `na.strings` - set the character that represents a missing value
- `skip` - number of lines to skip before starting to read
- `colClasses`
#### read.csv()
```{r}
cameraData <- read.csv("./data/cameras.csv")
```
`read.csv` sets `sep=","` and `header=TRUE`
### 1.2.2 {readr}
#### read_csv()
```{r}
library(readr)
ozone <- read_csv("data/hourly_44201_2014.csv", col_types = "ccccinnccccccncnncccccc")
```
`col_types=` c = character, i = integer, n = number, d = double, l = logical, D = date, T = date time, t = time, ? = guess, or _/- to skip the column
## 1.3 From Excel files
### 1.3.1 {readxl}
#### read_excel()
```{r}
download.file(fileUrl,destfile="./data/cameras.xlsx",mode="wb")
library(readxl)
cameraData <- read_excel("./data/cameras.xlsx",sheet=1,col_names = TRUE,range=cell_limits(ul=c(18,7),lr=c(23,15)))
```
## 1.3 From XML or Html
### 1.3.1 {XML}
```{r}
library(XML)
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE) # or htmlTreeParse() if from Html
```
`useInternal=TRUE` get all the different nodes inside of the file
1. Inspect the data 
```{r}
# get rootNode, the wrapper for the entire document
rootNode <- xmlRoot(doc)
# get the name of the document
xmlName(rootNode)
# get all the nested elements within the rootNode
names(rootNode)
```

```{r}
# Directly access parts of the XML document
rootNode[[1]]
# access subcomponent
rootNode[[1]][[1]]
```
2. Programatically extract parts of the file
```{r}
# get all values
xmlSApply(rootNode,xmlValue)
```
To be more specific, use [XPath](http://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf)
- `/node` Top level node
- `//node` Node at any level
- `node[@attr-name]` Node with an attribute name
- `node[@attr-name='bob']` Node with attribute name attr-name='bob'
```{r}
# examples
xpathSApply(rootNode,"//name",xmlValue)
xpathSApply(rootNode,"//price",xmlValue)
```
2.1 Extract content by attributes
```{r}
# example
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileUrl,useInternal=TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
teams <- xpathSApply(doc,"//li[@class='team-name']",xmlValue)
```
### 1.3.2 Notes and further resources
- Official XML tutorials [short](http://www.omegahat.org/RSXML/shortIntro.pdf), [long](http://www.omegahat.org/RSXML/shortIntro.pdf)
- [An outstanding guide to the XML package](https://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf)
## 1.4 From JSON
### 1.4.1 {jsonlite}
```{r}
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
```
1. Inspect the data (nested objects)
```{r}
names(jsonData)
jsonData$name

names(jsonData$owner)
jsonData$owner$login
```
2. Writing data frames to JSON
```{r}
myjson <- toJSON(iris, pretty=TRUE)
# print the data
cat(myjson)
```
`pretty=TRUE` give nice indentations so it's easy to read
### 1.4.2 Further resources
- [http://www.json.org/](http://www.json.org/)
- [A good tutorial on jsonlite](https://www.r-bloggers.com/new-package-jsonlite-a-smarter-json-encoderdecoder/)
- [jsonlite vignette](https://cran.r-project.org/web/packages/jsonlite/vignettes/json-mapping.pdf)
## 1.5 From MySQL
### 1.5.1 {RMySQL}
1. Connect and list databases
```{r}
library(RMySQL)
ucscDb <- dbConnect(MySQL(),user="genome", 
                    host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb,"show databases;"); dbDisconnect(ucscDb)
```
2. Connect to specific database and list tables
```{r}
hg19 <- dbConnect(MySQL(),user="genome", db="hg19",
                    host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
```
3. Get dimensions of a specific table
```{r}
# get column names
dbListFields(hg19,"affyU133Plus2")
# get number of rows
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
```
4. Read from the table
```{r}
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
```
4.1 Select a specific subset
```{r}
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query)
affyMisSmall <- fetch(query,n=10); dbClearResult(query)
dim(affyMisSmall)
```
5. Close the connection
```{r}
dbDisconnect(hg19)
```
### 1.5.2 Further resources
- [RMySQL vignette](https://cran.r-project.org/web/packages/RMySQL/RMySQL.pdf)
- [List of MySQL commands](http://www.pantz.org/software/mysql/mysqlcommands.html)
- A nice blog post summarizing [some other commands](https://www.r-bloggers.com/mysql-and-r/)
## 1.6 From HDF5
### 1.6.1 {rhdf5}
```{r}
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
```
1. Create HDF5 file
```{r}
created = h5createFile("example.h5")
```
1.1 Create groups
```{r}
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/foobaa")
h5ls("example.h5")
```
1.2 Write to groups
```{r}
A = matrix(1:10,nr=5,nc=2)
h5write(A, "example.h5","foo/A")
B = array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5","foo/foobaa/B")
h5ls("example.h5")
```
1.3 Write a data set
```{r}
df = data.frame(1L:5L,seq(0,1,length.out=5),
  c("ab","cde","fghi","a","s"), stringsAsFactors=FALSE)
h5write(df, "example.h5","df")
h5ls("example.h5")
```
2. Read data
```{r}
readA = h5read("example.h5","foo/A")
readB = h5read("example.h5","foo/foobaa/B")
readdf= h5read("example.h5","df")
readA
```
3. Write and read chunks(subsets)
```{r}
h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))
h5read("example.h5","foo/A")
```
`index=list(1:3,1)` give you indices for the dimensions to read/write
#### 1.6.2 Further resources
- [The rhdf5 tutorial](http://www.bioconductor.org/packages/release/bioc/html/rhdf5.html)
- The HDF group has [informaton on HDF5 in general](https://portal.hdfgroup.org/display/HDF5/HDF5)
## 1.7 From Web
### 1.7.1 {base}
#### readLines()
```{r}
# open a connection
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
# close the connection
close(con)
```
### 1.7.2 {XML}
```{r}
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)

xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
```
`useInternalNodes=T` gets the complete structure out
### 1.7.3 {httr}
#### GET()
```{r}
library(httr)
# GET the URL
html2 = GET(url)
# extract the content from that HTML page as a text
content2 = content(html2,as="text")
# parse the content
parsedHtml = htmlParse(content2,asText=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
```
1. Access websites with passwords
```{r}
pg2 = GET("http://httpbin.org/basic-auth/user/passwd",
    authenticate("user","passwd"))
```
1.1 Use handles (to store authentication)
```{r}
google = handle("http://google.com")
pg1 = GET(handle=google,path="/")
pg2 = GET(handle=google,path="search")
```
### 1.7.4 Further resources
- [R Bloggers](https://www.r-bloggers.com/) has a number of examples of web scraping
- The [httr help file](https://cran.r-project.org/web/packages/httr/httr.pdf) has useful examples
## 1.8 From APIs
### 1.8.1 {httr}
1. Access Website from R
```{r}
# example 1: Twitter
library(httr)
myapp = oauth_app("twitter",
                   key="yourConsumerKeyHere",secret="yourConsumerSecretHere")
sig = sign_oauth1.0(myapp,
                     token = "yourTokenHere",
                      token_secret = "yourTokenSecretHere")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
```

```{r}
# example 2: GitHub
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. To make your own application, register at 
#    https://github.com/settings/developers. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#    Replace your key and secret below.
myapp <- oauth_app("datasciencespecialization",
                   key = "key",
                   secret = "secret")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
# OR:
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos"))
stop_for_status(req)
content(req)
```
2. Convert the json object
```{r}
# example 1
# return a structured R object, which is a little bit hard to read
json1 = content(homeTL)
```
### 1.8.2 {jsonlite}
```{r}
# example 1
# reformat it as a data frame where each row corresponds to a tweet in the user's timeline
json2 = jsonlite::fromJSON(toJSON(json1))
```

```{r}
# example 2
library(jsonlite)
repo <- fromJSON(toJSON(content(req)))
```
## 1.9 From image
- [jpeg](https://cran.r-project.org/web/packages/jpeg/index.html)
- [readbitmap](https://cran.r-project.org/web/packages/readbitmap/index.html)
- [png](https://cran.r-project.org/web/packages/png/index.html)
- [EBImage (Bioconductor)](http://www.bioconductor.org/packages/2.13/bioc/html/EBImage.html)
## 1.10 From GIS data
- [rgdal](https://cran.r-project.org/web/packages/rgdal/index.html)
- [rgeos](https://cran.r-project.org/web/packages/rgeos/index.html)
- [raster](https://cran.r-project.org/web/packages/raster/index.html)
## 1.11 From music data
- [tuneR](https://cran.r-project.org/web/packages/tuneR/)
- [seewave](http://rug.mnhn.fr/seewave/)

# 2. Step 2 Clean the data
## 2.1 Data transformation
### 2.1.1 Subset
#### 2.1.1.1 {base}
1. Position or name
```{r}
# subset by colunmns, x is a data frame
X[,1]
# or
X[1]
# or
X[,'var1']

# subset by rows and colunmns
X[1:2,'var2']
```
2. Logicals (and, or, %in%)
```{r}
X[(X$var1 <= 3 & X$var3 > 11),]
X[(X$var1 <= 3 | X$var3 > 15),]
restData[restData$zipCode %in% c("21212","21213"),]
```
3. Deal with missing values
```{r}
X[which(X$var2 > 8),]
```
`which()` returns the indices where conditions are met
#### 2.1.1.2 {dplyr} or {tidyverse}
##### filter() (rows)
```{r}
donor %>% filter(amount > 100)
donor %>% filter(! type %in% 'Candidate')
```
Operators for conditions: `!, %in%, >, >=, <, <=, ==, &, |`
##### select() (columns)
```{r}
select(chicago, 1:5)
select(chicago, city:dptp)
select(chicago, -(city:dptp))
```
### 2.1.2 Reorder
#### 2.1.2.1 {dplyr} or {tidyverse}
##### arrange()
```{r}
arrange(chicago, desc(date))
```
#### 2.1.2.2 {base}
##### sort()
```{r}
sort(X$var1)
sort(X$var1,decreasing=TRUE)
sort(X$var2,na.last=TRUE)
```
##### order()
```{r}
X[order(X$var1),]
X[order(X$var1,X$var3),]
```
`order()` returns a permutation which rearranges its first argument into ascending or descending order, breaking ties by further arguments.
### 2.1.3 Add rows and columns
#### 2.1.3.1 {base}
```{r}
X$var4 <- rnorm(5)
```
##### cbind() and rbind()
```{r}
Y <- cbind(X,rnorm(5))
```
#### 2.1.3.2 {dplyr} or {tidyverse}
##### bind_rows() and bind_cols()
Append z to y as new rows. 
```{r}
bind_rows(y, z) 
```
Append z to y as new columns.
```{r}
bind_cols(y, z) 
```
Caution: matches rows by position.
### 2.1.4 Rename 
#### 2.1.4.1 {dplyr} or {tidyverse}
##### rename()
```{r}
rename(chicago, dewpoint = dptp, pm25 = pm25tmean2)
```
### 2.1.5 Create new variables
#### 2.1.5.1 {dplyr} or {tidyverse}
##### mutate()
```{r}
library(tidyverse)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
```
#### 2.1.5.2 {base} 
- Create sequences
```{r}
s1 <- seq(1,10,by=2)
s2 <- seq(1,10,length=3)
x <- c(1,3,8,25,100); seq(along = x)
```
- Create binary variables
```{r}
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
```
#### Common transforms
- `abs(x)` absolute value
- `sqrt(x)` square root
- `ceiling(x)` ceiling(3.475) is 4
- `floor(x)` floor(3.475) is 3
- `round(x,digits=n)` round(3.475,digits=2) is 3.48
- `signif(x,digits=n)` signif(3.475,digits=2) is 3.5
- `cos(x)`, `sin(x)` etc.
- `log(x)` natural logarithm
- `log2(x)`, `log10(x)` other common logs
- `exp(x)` exponentiating x
- [http://statmethods.net/management/functions.html](http://statmethods.net/management/functions.html)
### 2.1.6 Reshape the data
#### 2.1.6.1 {tidyr} or {tidyverse}
##### Convert columns into rows (with `gather()`)
```{r}
donor %>% gather(column_name, year, c(receipt_year, election_year))
```
`key=column_name` (new) name of column that store (old) column names  
`value=year` (new) name of column that store (old) values in (old) columns  
`c(receipt_year, election_year)` A selection of columns. If empty, all variables are selected. You can supply bare variable names, select all variables between x and z with `x:z`, exclude y with `-y`.
##### Convert rows into columns (with `spread()`)
```{r}
donor %>% spread(receipt_year, amount)
```
`key=receipt_year` (old) name or position of column that contains the names of the (new) columns  
`value=amount` (old) name of column that contains the values of the (new) columns
#### 2.1.6.2 {reshape2}
```{r}
library(reshape2)
```
##### melt() data frames
```{r}
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
```
`id=` creates an id value for car name, for gear and for cylinders. And then melt all the rest of the values. 
##### Cast (dcast()) data frames
```{r}
cylData <- dcast(carMelt, cyl ~ variable)
cylData <- dcast(carMelt, cyl ~ variable,mean)
```
Default aggregation function is length()
#### 2.1.6.3 Further resources
- [A nice reshape tutorial](https://www.slideshare.net/jeffreybreen/reshaping-data-in-r)
### 2.1.7 Aggregate values / Create a new variable
#### 2.1.7.1 {dplyr} or {tidyverse}
##### group_by(), summarise()
###### Example 1
In `donor`, which `type` received the more money in donations from `party` 'REPUBLICAN'?
```{r}
donor %>% group_by(type, party) %>% summarise(dollars = sum(amount, na.rm = TRUE))
```
- `group_by()` lists the variables by which to aggregate data
- `summarise()` creates a variable (dollars) and define the variable with an aggregation function
- Use `%>%` to 'link' `group_by()` and `summarise()`
- Aggregation functions: `n(), n_distinct(), sum(), mean(), max(), min()`, etc.
- `options(pillar.sigfig = 10)` to see more digits for numeric results in tibble
###### Example 2
In `donor`, what is the largest average donation `amount` for `contributor_state`?
```{r}
donor %>% 
  group_by(contributor_state) %>% 
  summarise(avg_donation = mean(amount, na.rm = TRUE)) %>%
  arrange(desc(avg_donation))
```
###### Example 3
```{r}
police %>% 
  transmute(
    initial_type_group = initial_type_group %>% as.character()
    , district_sector = district_sector %>% as.character()
    , event_clearance_group = event_clearance_group %>% as.character()
  ) %>%
  mutate(
    initial_type_group = ifelse(initial_type_group %in% NA, 'Unknown', initial_type_group)
  ) %>%
  filter(event_clearance_group %in% 'DISTURBANCES') %>% 
  group_by(initial_type_group, district_sector) %>% 
  summarise(n  = n()) %>%
  write_csv('tidyverse_exercise_output.csv')
```
###### Example 4
```{r}
police %>% 
  transmute(
    initial_type_group = initial_type_group %>% as.character()
    , district_sector = district_sector %>% as.character()
    , event_clearance_group = event_clearance_group %>% as.character()
  ) %>%
  mutate(
    initial_type_group = ifelse(initial_type_group %in% NA, 'Unknown', initial_type_group)
  ) %>%
  filter(event_clearance_group %in% 'DISTURBANCES') %>% 
  group_by(initial_type_group, district_sector) %>% 
  summarise(n  = n()) %>%
  filter(
    (initial_type_group %in% 'Unknown' & district_sector %in% 'W') |
    (initial_type_group %in% 'ROAD RAGE' & district_sector %in% 'L')
  )
```
#### 2.1.7.2 {base}
##### tapply()
```{r}
tapply(InsectSprays$count,InsectSprays$spray,sum)
```
sum up the counts, break down by spray
##### Another way - split()+apply()+unlist()
```{r}
spIns =  split(InsectSprays$count,InsectSprays$spray)
```
`split()` returns a list
```{r}
sprCount = lapply(spIns,sum)
unlist(sprCount)
```
##### Another way - split()+sapply()
```{r}
sapply(spIns,sum)
```
#### 2.1.7.3 {plyr}
##### ddply()
```{r}
library(plyr)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
```
`.()` are the variables to summarize
```{r}
spraySums <- ddply(InsectSprays,.(spray),summarize,sum=ave(count,FUN=sum))
```
##### Further resources
- A [tutorial](http://plyr.had.co.nz/09-user/) from the developer of plyr
- [A good plyr primer](https://www.r-bloggers.com/a-quick-primer-on-split-apply-combine-problems/)
### 2.1.8 Merge the data
#### 2.1.8.1 {dplyr} or {tidyverse}
##### Mutating Joins
Join matching rows from b to a.
```{r}
left_join(a, b, by = "x1")
```
Join matching rows from a to b. 
```{r}
right_join(a, b, by = "x1") 
```
Join data. Retain only rows in both sets. 
```{r}
inner_join(a, b, by = "x1") 
```
Join data. Retain all values, all rows.
```{r}
full_join(a, b, by = "x1") 
```
##### Filtering Joins
All rows in a that have a match in b. 
```{r}
semi_join(a, b, by = "x1") 
```
All rows in a that do not have a match in b
```{r}
anti_join(a, b, by = "x1") 
```
##### Set Operations
Rows that appear in both y and z. 
```{r}
intersect(y, z) 
```
Rows that appear in either or both y and z.
```{r}
union(y, z)
```
Rows that appear in y but not z.
```{r}
setdiff(y, z)
```
#### 2.1.8.2 {base}
##### merge()
```{r}
mergedData = merge(reviews,solutions,by.x="solution_id",by.y="id",all=TRUE)
```
`all=TRUE` full join
#### 2.1.8.3 Further resourece
- [The quick R data merging page](https://www.statmethods.net/management/merging.html)
## 2.2 Data types
### 2.2.1 Strings
#### 2.2.1.1 Transformation of upper/lower case
##### {base}
```{r}
tolower(names(cameraData))
toupper()
```
##### {stringr}
```{r}
str_to_lower()
str_to_upper()
str_to_upper(c("i", "ı"), locale = "tr")
str_to_title()
```
pick the set of rules to use by specifying a `locale`
#### 2.2.1.2 Sort and order
##### {stringr}
```{r}
x <- c("apple", "eggplant", "banana")

str_sort(x, locale = "en")  # English
#> [1] "apple"    "banana"   "eggplant"

str_sort(x, locale = "haw") # Hawaiian
#> [1] "apple"    "eggplant" "banana"
```
#### 2.2.1.3 Split
##### {base}
###### strsplit()+sapply()
```{r}
splitNames = strsplit(names(cameraData),"\\.")
```
`split="\\."` character vector containing regular expression(s) to use for splitting.
- strsplit() returns a list
- use escape character '\' because the period is a reserved character
Then extract the first element of splited names:
```{r}
splitNames[[6]][1]
firstElement <- function(x){x[1]}
sapply(splitNames,firstElement)
```
##### {stringr}
###### str_split()
```{r}
# split sentences into words
sentences %>%
  head(5) %>% 
  str_split(" ")
```
Because each component might contain a different number of pieces, this returns a list. If you’re working with a length-1 vector, the easiest thing is to just extract the first element of the list:
```{r}
"a|b|c|d" %>% 
  str_split("\\|") %>% 
  .[[1]]
```
use `simplify = TRUE` to return a matrix
```{r}
sentences %>%
  head(5) %>% 
  str_split(" ", simplify = TRUE)
```
request a maximum number of pieces
```{r}
fields <- c("Name: Hadley", "Country: NZ", "Age: 35")
fields %>% str_split(": ", n = 2, simplify = TRUE)
```
Instead of splitting up strings by patterns, you can also split up by character, line, sentence and word `boundary()`s:
```{r}
x <- "This is a sentence.  This is another sentence."
str_view_all(x, boundary("word"))

str_split(x, " ")[[1]]
str_split(x, boundary("word"))[[1]]
```
#### 2.2.1.4 Substitute
##### {base}
###### sub() and gsub()
```{r}
testName <- "this_is_a_test"

# sub only the first one
sub("_","",testName)

# sub all
gsub("_","",testName)
```
#### 2.2.1.5 Number of characters
##### {base}
```{r}
nchar("Jeffrey Leek")
```
##### {stringr}
```{r}
str_length(c("a", "R for data science", NA))
```
#### 2.2.1.6 Extract parts of the string / subset strings
##### {base}
```{r}
substr("Jeffrey Leek",1,7) # 1st to 7th characters
```
##### {stringr}
###### str_sub()
```{r}
x <- c("Apple", "Banana", "Pear")
str_sub(x, 1, 3)
# negative numbers count backwards from end
str_sub(x, -3, -1)
```
takes `start` and `end` arguments which give the (inclusive) position of the substring
```{r}
str_sub("a", 1, 5)
```
won’t fail if the string is too short: it will just return as much as possible
```{r}
str_sub(x, 1, 1) <- str_to_lower(str_sub(x, 1, 1))
x
```
can also use the assignment form to modify strings
#### 2.2.1.7 Combine strings
##### {base}
```{r}
# paste to get a string spereated with a space
paste("Jeffrey","Leek")
# paste to get a string without space
paste0("Jeffrey","Leek")
```
##### {stringr}
###### str_c()
```{r}
str_c("x", "y")
str_c("x", "y", sep = ", ") 

str_c("prefix-", c("a", "b", "c"), "-suffix")
#> [1] "prefix-a-suffix" "prefix-b-suffix" "prefix-c-suffix"
```
Use the `sep` argument to control how they’re separated
```{r}
str_c(c("x", "y", "z"), collapse = ", ")
#> [1] "x, y, z"
```
To collapse a vector of strings into a single string, use `collapse`
```{r}
name <- "Hadley"
time_of_day <- "morning"
birthday <- FALSE

str_c(
  "Good ", time_of_day, " ", name,
  if (birthday) " and HAPPY BIRTHDAY",
  "."
)
```
Objects of length 0 are silently dropped. This is particularly useful in conjunction with `if`
#### 2.2.1.8 Trim whitespace
##### {stringr}
```{r}
# removes whitespace from start and end of string
str_trim("Jeff      ")
```
#### 2.2.1.9 Regular expression
##### 2.2.1.9.1 Basic matches
`.` is used to refer to any character
```{r}
9.11
```
##### 2.2.1.9.2 Anchors
`^` represents the start of a line
```{r}
^i think
```
`$` represents the end of a line
```{r}
morning$
```
You can also match the boundary between words with `\b`. You can search for `\bsum\b` to avoid matching `summarise`, `summary`, `rowsum` and so on.  
##### 2.2.1.9.3 Character Classes with [] and alternatives
- `\d`: matches any digit.
- `\s`: matches any whitespace (e.g. space, tab, newline).
- `[abc]`: matches a, b, or c.
- `[^abc]`: matches anything except a, b, or c.
A character class containing a single character is a nice alternative to backslash escapes when you want to include a single metacharacter in a regex. Many people find this more readable.
```{r}
# Look for a literal character that normally has special meaning in a regex
str_view(c("abc", "a.c", "a*c", "a c"), "a[.]c")
str_view(c("abc", "a.c", "a*c", "a c"), ".[*]c")
str_view(c("abc", "a.c", "a*c", "a c"), "a[ ]")
```
This works for most (but not all) regex metacharacters: `$` `.` `|` `?` `*` `+` `(` `)` `[` `{`. Unfortunately, a few characters have special meaning even inside a character class and must be handled with backslash escapes: `]` `\` `^` and `-`.  
`|` "or"
```{r}
flood|fire
flood|earthquake|hurricane|coldfire
str_view(c("grey", "gray"), "gr(e|a)y")
```
list a set of characters we will accept at a given point in the match
```{r}
[Bb][Uu][Ss][Hh]

^[Ii] am

^[0-9][a-zA-Z]

^[Gg]ood|[Bb]ad
^([Gg]ood|[Bb]ad)
```
When used at the beginning of a character class, the "^" is also a metacharacter and indicates matching characters NOT in the indicated class
```{r}
[^?.]$
```
##### 2.2.1.9.4 Repetition
- `?`: 0 or 1
- `+`: 1 or more
- `*`: 0 or more
```{r}
x <- "1888 is the longest year in Roman numerals: MDCCCLXXXVIII"
str_view(x, "CC?")
str_view(x, "CC+")
str_view(x, 'C[LX]+')
```

```{r}
[Gg]eorge( [Ww]\.)? [Bb]ush
```

```{r}
(.*)
[0-9]+ (.*)[0-9]+
```
`{}` are referred to as interval quantifiers which specify the minimum and maximum number of matches of an expression
```{r}
[Bb]ush ([^ ]+ +){1,5}debate
```
specify the number of matches precisely:
- `{n}`: exactly n
- `{n,}`: n or more
- `{,m}`: at most m
- `{n,m}`: between n and m
```{r}
str_view(x, "C{2}")
str_view(x, "C{2,}")
str_view(x, "C{2,3}")
```
The greediness of `*` (longest possible match) can be turned off with the `?`
```{r}
^s(.*?)s$
str_view(x, 'C{2,3}?')
str_view(x, 'C[LX]+?')
```
##### 2.2.1.9.5 Grouping and backreferences
`()` not only limits the scope of alternatives divided by a `|`, but also can be used to "remember" text matched by the subexpression enclosed; We refer to the matched text with `\1`, `\2`, etc.
```{r}
+([a-zA-Z]+) +\1 +
str_view(fruit, "(..)\\1", match = TRUE)
```
##### 2.2.1.9.6 Other uses of regular expressions
###### apropos()
searches all objects available from the global environment
```{r}
apropos("replace")
```
###### dir()
lists all the files in a directory. The `pattern` argument takes a regular expression and only returns file names that match the pattern.
```{r}
# find all the R Markdown files in the current directory
head(dir(pattern = "\\.Rmd$"))
```
#### 2.2.1.10 Detect matches
##### {base}
###### grep() and grepl()
```{r}
grep("Alameda",cameraData$intersection)
table(grepl("Alameda",cameraData$intersection))
grep("Alameda",cameraData$intersection,value=TRUE)

# subset
cameraData2 <- cameraData[!grepl("Alameda",cameraData$intersection),]
```
`pattern="Alameda"` character string containing a regular expression (or character string for fixed = TRUE) to be matched
- `grep(value = FALSE)` returns a vector of the indices of the elements of x that yielded a match (or not, for `invert = TRUE`)
- `grep(value = TRUE)` returns a character vector containing the selected elements of x
- `grepl` returns a logical vector (match or not for each element of x)
##### {stringr}
###### str_detect()
```{r}
x <- c("apple", "banana", "pear")
str_detect(x, "e")
```
returns a logical vector the same length as the input
```{r}
# How many common words start with t?
sum(str_detect(words, "^t"))
#> [1] 65
# What proportion of common words end with a vowel?
mean(str_detect(words, "[aeiou]$"))
#> [1] 0.277
```
###### str_detect() or str_subset(): Logical subsetting
select the elements that match a pattern
```{r}
words[str_detect(words, "x$")]
#> [1] "box" "sex" "six" "tax"
str_subset(words, "x$")
#> [1] "box" "sex" "six" "tax"

df %>% 
  filter(str_detect(words, "x$"))
```
###### str_count()
how many matches are there in a string
```{r}
x <- c("apple", "banana", "pear")
str_count(x, "a")
#> [1] 1 3 1

# On average, how many vowels per word?
mean(str_count(words, "[aeiou]"))
#> [1] 1.99
```
#### 2.2.1.11 Extract matches
##### {stringr}
###### str_extract()
extract the actual text of a match
```{r}
colours <- c("red", "orange", "yellow", "green", "blue", "purple")
colour_match <- str_c(colours, collapse = "|")
has_colour <- str_subset(sentences, colour_match)
matches <- str_extract(has_colour, colour_match)
```
###### str_extract_all() 
get all matches
```{r}
more <- sentences[str_count(sentences, colour_match) > 1]
str_view_all(more, colour_match)
str_extract_all(more, colour_match)
```
`simplify = TRUE`: return a matrix with short matches expanded to the same length as the longest
```{r}
str_extract_all(more, colour_match, simplify = TRUE)

x <- c("a", "a b", "a b c")
str_extract_all(x, "[a-z]", simplify = TRUE)
```
###### str_match()
gives each individual component. Instead of a character vector, it returns a matrix, with one column for the complete match followed by one column for each group:
```{r}
noun <- "(a|the) ([^ ]+)"

has_noun <- sentences %>%
  str_subset(noun)
has_noun %>% 
  str_match(noun)
str_match_all()
```
##### {tidyr}
###### extract() 
If your data is in a tibble. It works like `str_match()` but requires you to name the matches, which are then placed in new columns:
```{r}
tibble(sentence = sentences) %>% 
  tidyr::extract(
    sentence, c("article", "noun"), "(a|the) ([^ ]+)", 
    remove = FALSE
  )
```
#### 2.2.1.12 Replace matches
##### {stringr}
###### str_replace(), str_replace_all()
replace matches with new strings
```{r}
# replace a pattern with a fixed string
x <- c("apple", "pear", "banana")
str_replace(x, "[aeiou]", "-")
str_replace_all(x, "[aeiou]", "-")
```
With `str_replace_all()` you can perform multiple replacements by supplying a named vector:
```{r}
x <- c("1 house", "2 cars", "3 people")
str_replace_all(x, c("1" = "one", "2" = "two", "3" = "three"))
#> [1] "one house"    "two cars"     "three people"
```
Instead of replacing with a fixed string you can use backreferences to insert components of the match.
```{r}
# flip the order of the second and third words
sentences %>% 
  str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2")
```
#### 2.2.1.13 Other types of pattern
##### {base}
###### regex()
When you use a pattern that’s a string, it’s automatically wrapped into a call to `regex()`
```{r}
bananas <- c("banana", "Banana", "BANANA")
str_view(bananas, regex("banana", ignore_case = TRUE))
```
`ignore_case = TRUE` allows characters to match either their uppercase or lowercase forms. This always uses the current locale.
```{r}
x <- "Line 1\nLine 2\nLine 3"
str_extract_all(x, "^Line")[[1]]
#> [1] "Line"
str_extract_all(x, regex("^Line", multiline = TRUE))[[1]]
#> [1] "Line" "Line" "Line"
```
`multiline = TRUE` allows `^` and `$` to match the start and end of each line rather than the start and end of the complete string.
```{r}
phone <- regex("
  \\(?     # optional opening parens
  (\\d{3}) # area code
  [) -]?   # optional closing parens, space, or dash
  (\\d{3}) # another three numbers
  [ -]?    # optional space or dash
  (\\d{3}) # three more numbers
  ", comments = TRUE)

str_match("514-791-8141", phone)
```
`comments = TRUE` allows you to use comments and white space to make complex regular expressions more understandable. Spaces are ignored, as is everything after `#`. To match a literal space, you’ll need to escape it: `"\\ "`.
`dotall = TRUE` allows `.` to match everything, including `\n`.
###### fixed()
matches exactly the specified sequence of bytes. It ignores all special regular expressions and operates at a very low level. This allows you to avoid complex escaping and can be much faster than regular expressions.
###### coll()
compare strings using standard **coll**ation rules. This is useful for doing case insensitive matching. Note that `coll()` takes a locale parameter that controls which rules are used for comparing characters.
```{r}
a1 <- "\u00e1"
a2 <- "a\u0301"
c(a1, a2)
#> [1] "á" "á"
a1 == a2
#> [1] FALSE

# use coll() to respect human character comparison rules
str_detect(a1, fixed(a2))
#> [1] FALSE
str_detect(a1, coll(a2))
#> [1] TRUE
```

```{r}
# That means you also need to be aware of the difference
# when doing case insensitive matches:
i <- c("I", "İ", "i", "ı")
i
#> [1] "I" "İ" "i" "ı"

str_subset(i, coll("i", ignore_case = TRUE))
#> [1] "I" "i"
str_subset(i, coll("i", ignore_case = TRUE, locale = "tr"))
#> [1] "İ" "i"
```
because the rules for recognising which characters are the same are complicated, `coll()` is relatively slow compared to `regex()` and `fixed()`.
### 2.2.2 Factor
#### 2.2.2.1 Create factor variables
##### 2.2.2.1.1 {base}
```{r}
restData$zcf <- factor(restData$zipCode)
```

```{r}
restData$zipGroups = cut(restData$zipCode,breaks=quantile(restData$zipCode))
```
apply `cut()` to quantitative variable (zipCode). `breaks=` break up according to a list of value (the quantiles to that zip code). Returns a factor variable.
```{r}
yesnofac = factor(yesno,levels=c("yes","no"))
relevel(yesnofac,ref="no")
```
if no `levels=c("yes","no")`, by default, `factor()` treats the lowest value alphabetically as the first factor variable.
```{r}
x1 <- c("Dec", "Apr", "Jan", "Mar")
x2 <- c("Dec", "Apr", "Jam", "Mar")
month_levels <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun", 
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)
```
And any values not in the set will be silently converted to NA
```{r}
y2 <- factor(x2, levels = month_levels)
```
If you want a warning, you can use `readr::parse_factor()`
```{r}
y2 <- parse_factor(x2, levels = month_levels)
```
Sometimes you’d prefer that the order of the levels match the order of the first appearance in the data. You can do that when creating the factor by setting levels to `unique(x)`, or after the fact, with `forcats::fct_inorder()`:
```{r}
f1 <- factor(x1, levels = unique(x1))
f2 <- x1 %>% factor() %>% fct_inorder()
```
##### 2.2.2.1.2 {Hmisc}
###### cut2()
```{r}
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode,g=4)
```
`g=` number of quantile groups
#### 2.2.2.2 Levels of factor variables
If you ever need to access the set of valid levels directly, you can do so with `levels()`:
```{r}
levels(f2)
```
When factors are stored in a tibble, you can’t see their levels so easily. One way to see them is with `count()`:
```{r}
gss_cat %>%
  count(race)
```
Or with a bar chart:
```{r}
ggplot(gss_cat, aes(race)) +
  geom_bar()
```
By default, ggplot2 will drop levels that don’t have any values. You can force them to display with:
```{r}
ggplot(gss_cat, aes(race)) +
  geom_bar() +
  scale_x_discrete(drop = FALSE)
```
#### 2.2.2.3 Modify factor order
##### {base}
```{r}
schoolPub$High.Grade.=factor(schoolPub$High.Grade.,
                             levels = levelCat,
                             labels = levelCat,
                             ordered = T)
```
##### {forcats}
###### fct_reorder()
```{r}
ggplot(relig_summary, aes(tvhours, fct_reorder(relig, tvhours))) +
  geom_point()

relig_summary %>%
  mutate(relig = fct_reorder(relig, tvhours)) %>%
  ggplot(aes(tvhours, relig)) +
    geom_point()
```
- `f`, the factor whose levels you want to modify.
- `x`, a numeric vector that you want to use to reorder the levels.
- Optionally, `fun`, a function that’s used if there are multiple values of `x` for each value of `f`. The default value is `median`.
###### fct_relevel()
takes a factor, `f`, and then any number of levels that you want to move to the front of the line.
```{r}
ggplot(rincome_summary, aes(age, fct_relevel(rincome, "Not applicable"))) +
  geom_point()
```
###### fct_reorder2()
useful when you are colouring the lines on a plot. `fct_reorder2()` reorders the factor by the `y` values associated with the largest `x` values. This makes the plot easier to read because the line colours line up with the legend.
```{r}
by_age <- gss_cat %>%
  filter(!is.na(age)) %>%
  count(age, marital) %>%
  group_by(age) %>%
  mutate(prop = n / sum(n))

ggplot(by_age, aes(age, prop, colour = marital)) +
  geom_line(na.rm = TRUE)

ggplot(by_age, aes(age, prop, colour = fct_reorder2(marital, age, prop))) +
  geom_line() +
  labs(colour = "marital")
```
###### fct_infreq()
order levels in increasing frequency: this is the simplest type of reordering because it doesn’t need any extra variables. You may want to combine with `fct_rev()`
```{r}
gss_cat %>%
  mutate(marital = marital %>% fct_infreq() %>% fct_rev()) %>%
  ggplot(aes(marital)) +
    geom_bar()
```
#### 2.2.2.4 Modify factor levels
##### {forcats}
###### fct_recode()
allows you to recode, or change, the value of each level.
```{r}
gss_cat %>% count(partyid)
gss_cat %>%
  mutate(partyid = fct_recode(partyid,
    "Republican, strong"    = "Strong republican",
    "Republican, weak"      = "Not str republican",
    "Independent, near rep" = "Ind,near rep",
    "Independent, near dem" = "Ind,near dem",
    "Democrat, weak"        = "Not str democrat",
    "Democrat, strong"      = "Strong democrat"
  )) %>%
  count(partyid)
```
To combine groups, you can assign multiple old levels to the same new level:
```{r}
gss_cat %>%
  mutate(partyid = fct_recode(partyid,
    "Republican, strong"    = "Strong republican",
    "Republican, weak"      = "Not str republican",
    "Independent, near rep" = "Ind,near rep",
    "Independent, near dem" = "Ind,near dem",
    "Democrat, weak"        = "Not str democrat",
    "Democrat, strong"      = "Strong democrat",
    "Other"                 = "No answer",
    "Other"                 = "Don't know",
    "Other"                 = "Other party"
  )) %>%
  count(partyid)
```
###### fct_collapse()
a useful variant of `fct_recode()`; collapse a lot of levels
```{r}
gss_cat %>%
  mutate(partyid = fct_collapse(partyid,
    other = c("No answer", "Don't know", "Other party"),
    rep = c("Strong republican", "Not str republican"),
    ind = c("Ind,near rep", "Independent", "Ind,near dem"),
    dem = c("Not str democrat", "Strong democrat")
  )) %>%
  count(partyid)
```
###### fct_lump()
lump together all the small groups to make a plot or table simpler
```{r}
gss_cat %>%
  mutate(relig = fct_lump(relig)) %>%
  count(relig)
```
The default behaviour is to progressively lump together the smallest groups, ensuring that the aggregate is still the smallest group.
```{r}
gss_cat %>%
  mutate(relig = fct_lump(relig, n = 10)) %>%
  count(relig, sort = TRUE) %>%
  print(n = Inf)
```
`n`: specify how many groups (excluding other) to keep
#### 2.2.2.5 Further resources
- A nice [lecture on categorical and factor variables](https://www.stat.berkeley.edu/classes/s133/factors.html)
- [Wrangling categorical data in R](https://peerj.com/preprints/3163/)
### 2.2.3 Date and time
#### 2.2.3.1 {base}
##### format date
- `%d` day as number (0-31)
- `%a` abbreviated weekday
- `%A` unabbreviated weekday
- `%m` month (00-12)
- `%b` abbreviated month
- `%B` unabbrevidated month
- `%y` 2 digit year
- `%Y` four digit year
```{r}
format(Sys.Date(),"%a %b %d")
```
##### create date
```{r}
x = c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z = as.Date(x, "%d%b%Y")
z[1] - z[2]
as.numeric(z[1]-z[2])
```
##### attribute of date
```{r}
weekdays(d2)
months(d2)

# days from origin
julian(d2) 
```
#### 2.2.3.2 {lubridate}
##### 2.2.3.2.1 Create date/time
1. From strings
```{r}
mdy("08/04/2013")
dmy("03-04-2013")
ymd(20170131)

ymd("2017-01-31")
mdy("January 31st, 2017")
dmy("31-Jan-2017")

ymd_hms("2011-08-03 10:15:03")
ymd_hms("2011-08-03 10:15:03",tz="Pacific/Auckland")

x = dmy(c("1jan2013", "2jan2013", "31mar2013", "30jul2013"))
```
2. From individual components
`make_date()`, `make_datetime()`
```{r}
flights %>% 
  select(year, month, day, hour, minute) %>% 
  mutate(departure = make_datetime(year, month, day, hour, minute))
```
when you use date-times in a numeric context (like in a histogram), 1 means 1 second, so a binwidth of 86400 means one day. For dates, 1 means 1 day.
```{r}
flights_dt %>% 
  ggplot(aes(dep_time)) + 
  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day

flights_dt %>% 
  filter(dep_time < ymd(20130102)) %>% 
  ggplot(aes(dep_time)) + 
  geom_freqpoly(binwidth = 600) # 600 s = 10 minutes
```
3. From other types
```{r}
as_datetime(today())
as_date(now())
```
Sometimes you’ll get date/times as numeric offsets from the “Unix Epoch”, 1970-01-01. If the offset is in seconds, use as_datetime(); if it’s in days, use as_date().
```{r}
as_datetime(60 * 60 * 10)
#> [1] "1970-01-01 10:00:00 UTC"
as_date(365 * 10 + 2)
#> [1] "1980-01-01"
```
##### 2.2.3.2.2 Date-time components
###### Get components
- `year()`
- `month()`
- `mday()` (day of the month)
- `yday()` (day of the year)
- `wday()` (day of the week)
- `hour()`
- `minute()`
- `second()`
```{r}
# weekday
wday(x[1])
# show weekday abbreviation
wday(x[1],label=TRUE)
```
For `month()` and `wday()` you can set `label = TRUE` to return the abbreviated name of the month or day of the week. Set `abbr = FALSE` to return the full name.
```{r}
datetime <- ymd_hms("2016-07-08 12:34:56")

month(datetime, label = TRUE)
wday(datetime, label = TRUE, abbr = FALSE)
```
###### Rounding
`floor_date()`, `round_date()`, and `ceiling_date()`. Each function takes a vector of dates to adjust and then the name of the unit round down (floor), round up (ceiling), or round to.
```{r}
flights_dt %>% 
  count(week = floor_date(dep_time, "week")) %>% 
  ggplot(aes(week, n)) +
    geom_line()
```
###### Set components
```{r}
(datetime <- ymd_hms("2016-07-08 12:34:56"))
year(datetime) <- 2020
month(datetime) <- 01
hour(datetime) <- hour(datetime) + 1
```
`update()` allows you to set multiple values at once.
```{r}
update(datetime, year = 2020, month = 2, mday = 2, hour = 2)
```
If values are too big, they will roll-over:
```{r}
ymd("2015-02-01") %>% 
  update(mday = 30)
ymd("2015-02-01") %>% 
  update(hour = 400)
```
use `update()` to show the distribution of flights across the course of the day for every day of the year:
```{r}
flights_dt %>% 
  mutate(dep_hour = update(dep_time, yday = 1)) %>% 
  ggplot(aes(dep_hour)) +
    geom_freqpoly(binwidth = 300)
```
Setting larger components of a date to a constant is a powerful technique that allows you to explore patterns in the smaller components.
##### 2.2.3.2.3 Time spans
###### duration
```{r}
h_age <- today() - ymd(19791014)
as.duration(h_age)
```
Durations always record the time span in seconds. Larger units are created by converting minutes, hours, days, weeks, and years to seconds at the standard rate (60 seconds in a minute, 60 minutes in an hour, 24 hours in day, 7 days in a week, 365 days in a year).
```{r}
dseconds(15)
#> [1] "15s"
dminutes(10)
#> [1] "600s (~10 minutes)"
dhours(c(12, 24))
#> [1] "43200s (~12 hours)" "86400s (~1 days)"
ddays(0:5)
#> [1] "0s"                "86400s (~1 days)"  "172800s (~2 days)"
#> [4] "259200s (~3 days)" "345600s (~4 days)" "432000s (~5 days)"
dweeks(3)
#> [1] "1814400s (~3 weeks)"
dyears(1)
#> [1] "31536000s (~52.14 weeks)"
```

```{r}
2 * dyears(1)
dyears(1) + dweeks(12) + dhours(15)
tomorrow <- today() + ddays(1)
last_year <- today() - dyears(1)
```
###### Periods
Periods are time spans but don’t have a fixed length in seconds, instead they work with “human” times, like days and months. That allows them work in a more intuitive way:
```{r}
one_pm
#> [1] "2016-03-12 13:00:00 EST"
one_pm + days(1)
#> [1] "2016-03-13 13:00:00 EDT"
```

```{r}
seconds(15)
minutes(10)
hours(c(12, 24))
days(7)
months(1:6)
weeks(3)
years(1)

10 * (months(6) + days(1))
days(50) + hours(25) + minutes(2)
```
Compared to durations, periods are more likely to do what you expect:
```{r}
# A leap year
ymd("2016-01-01") + dyears(1)
#> [1] "2016-12-31"
ymd("2016-01-01") + years(1)
#> [1] "2017-01-01"

# Daylight Savings Time
one_pm + ddays(1)
#> [1] "2016-03-13 14:00:00 EDT"
one_pm + days(1)
#> [1] "2016-03-13 13:00:00 EDT"
```
###### Intervals
An **interval** is a duration with a starting point: that makes it precise so you can determine exactly how long it is:
```{r}
next_year <- today() + years(1)
(today() %--% next_year) / ddays(1)
```
To find out how many periods fall into an interval, you need to use integer division:
```{r}
(today() %--% next_year) %/% days(1)
```
###### Summary
If you only care about physical time, use a duration; if you need to add human times, use a period; if you need to figure out how long a span is in human units, use an interval.
##### 2.2.3.2.4 Time zones
In R, the time zone is an attribute of the date-time that only controls printing. For example, these three objects represent the same instant in time:
```{r}
(x1 <- ymd_hms("2015-06-01 12:00:00", tz = "America/New_York"))
(x2 <- ymd_hms("2015-06-01 18:00:00", tz = "Europe/Copenhagen"))
(x3 <- ymd_hms("2015-06-02 04:00:00", tz = "Pacific/Auckland"))

#> Time difference of 0 secs
x1 - x2
x1 - x3
```
Unless otherwise specified, lubridate always uses UTC. UTC (Coordinated Universal Time) does not have DST, which makes a convenient representation for computation. Operations that combine date-times, like c(), will often drop the time zone. In that case, the date-times will display in your local time zone:
```{r}
x4 <- c(x1, x2, x3)
```
##### Change the time zone
1. Keep the instant in time the same, and change how it’s displayed. Use this when the instant is correct, but you want a more natural display.
```{r}
x4a <- with_tz(x4, tzone = "Australia/Lord_Howe")

# no time difference
x4a - x4
```
2. Change the underlying instant in time. Use this when you have an instant that has been labelled with the incorrect time zone, and you need to fix it.
```{r}
x4b <- force_tz(x4, tzone = "Australia/Lord_Howe")

x4b - x4
#> Time differences in hours
#> [1] -14.5 -14.5 -14.5
```
##### 2.2.3.2.5 Further resources and notes
- More information in this nice [lubridate tutorial](http://www.r-statistics.com/2012/03/do-more-with-dates-and-times-in-r-with-lubridate-1-1-0/)
- The [lubridate vignette](http://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html) is the same content
- Ultimately you want your dates and times as class "Date" or the classes "POSIXct", "POSIXlt". For more information type `?POSIXlt`
- POSIXct’s are always easier to work with, so if you find you have a POSIXlt, you should always convert it to a regular date time `lubridate::as_date_time()`.
## 2.3 Further resources
- [Data Wrangling with {dplyr} and {tidyr} Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)
- Andrew Jaffe's [lecture notes](http://www.biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf)

# 3. Step 3 Exploratory Data Analysis
## 3.1 Summarize the data
### 3.1.1 Basic summary
#### {base}
Look at a bit of the data
```{r}
head(restData,n=3)
tail(restData,n=3)
```
Five Number Summary
```{r}
summary(restData)
summary(pollution$pm25)
```
More in depth information
```{r}
str(restData)
```
### 3.1.2 Distribution
#### 3.1.2.1 One dimension
##### {base}
###### Quantiles of quantitative variables
```{r}
quantile(restData$councilDistrict,na.rm=TRUE)
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9))
```
###### table()
```{r}
table(restData$zipCode,useNA="ifany")
table(restData$councilDistrict,restData$zipCode)
```
`useNA="ifany"` if there are any missing values, they'll be an added column to this table, which will be NA, and it'll tell you the number of missing values there is.
###### Boxplot
```{r}
boxplot(pollution$pm25, col = "blue")
```
###### Histogram
```{r}
hist(pollution$pm25, col = "green", breaks = 100)
rug(pollution$pm25)
```
`rug()` plots all of the points in your dataset along underneath the histogram  
`breaks=100` the number of bars in the histogram
###### Overlaying Features
```{r}
abline(h = 12)
abline(v = median(pollution$pm25), col = "magenta", lwd = 4)
```
`h=` horizontal line  
`v=` vertical line  
`lwd=`line width
###### Barplot
```{r}
barplot(table(pollution$region), col = "wheat", main = "Number of Counties in Each Region")
```
#### 3.1.2.2 Two dimensions
##### {base}
###### Multiple Boxplots
```{r}
boxplot(pm25 ~ region, data = pollution, col = "red")
```
`pm25 ~ region` `pm25` is a numeric vector of data values to be split into groups according to the grouping variable `region` (usually a factor)
###### Multiple Histograms
```{r}
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))
hist(subset(pollution, region == "east")$pm25, col = "green")
hist(subset(pollution, region == "west")$pm25, col = "green")
```
`par()` set or query graphical parameters  
`mar=` A numerical vector of the form c(bottom, left, top, right) which gives the number of lines of margin to be specified on the four sides of the plot.  
`mfrow=` A vector of the form c(nr, nc). Subsequent figures will be drawn in an nr-by-nc array on the device by columns (mfcol), or rows (mfrow), respectively.
###### Scatterplot
```{r}
with(pollution, plot(latitude, pm25, col = region))
abline(h = 12, lwd = 2, lty = 2)
```
`col=region` break out color groups by region  
`lty` line type
###### Multiple Scatterplots
```{r}
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1))
with(subset(pollution, region == "west"), plot(latitude, pm25, main = "West"))
with(subset(pollution, region == "east"), plot(latitude, pm25, main = "East"))
```
### 3.1.3 Check for missing values
#### {mice}
md.pattern()
```{r}
md.pattern(bc_data, plot = FALSE)
```
#### {base}
```{r}
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
```
Row and column sums
```{r}
colSums(is.na(restData))
all(colSums(is.na(restData))==0)
```
### 3.1.4 Values with specific characteristics
#### {base}
```{r}
table(restData$zipCode %in% c("21212","21213"))
```
##### Cross tables
```{r}
xt <- xtabs(Freq ~ Gender + Admit,data=DF)
```
`Freq` the variable that you want to be displayed in the table  
`Gender + Admit` break that down by variables
```{r}
xt = xtabs(breaks ~.,data=warpbreaks)
```
`~.` break down by all the variables in the data set
##### Flat tables
```{r}
ftable(xt)
```
`ftable` make flat tables from the crosstabs. It will summarize the data in a much smaller, more compact form. So it's easier to see.
### 3.1.5 Size of a data set
#### {base}
```{r}
object.size(fakeData)
print(object.size(fakeData),units="Mb")
```
## 3.2 Plotting
### 3.2.1 {base}
#### 3.2.1.1 Parameters
Many base plotting functions share a set of parameters. Here are a few key ones:
- `pch`: the plotting symbol (default is open circle)
- `lty`: the line type (default is solid line), can be dashed, dotted, etc.
- `lwd`: the line width, specified as an integer multiple
- `col`: the plotting color, specified as a number, string, or hex code; the colors() function gives you a vector of colors by name
- `xlab`: character string for the x-axis label
- `ylab`: character string for the y-axis label
##### par(): specify global graphics parameters
These parameters can be overridden when specified as arguments to specific plotting functions. (Use `dev.off` or `plot.new` to reset to the defaults.)
- `las`: the orientation of the axis labels on the plot
- `bg`: the background color
- `mar`: the margin size
- `oma`: the outer margin size (default is 0 for all sides)
- `mfrow`: number of plots per row, column (plots are filled row-wise)
- `mfcol`: number of plots per row, column (plots are filled column-wise)
#### 3.2.1.2 Plotting functions
- `plot`: make a scatterplot, or other type of plot depending on the class of the object being plotted
- `lines`: add lines to a plot, given a vector x values and a corresponding vector of y values (or a 2-column matrix); this function just connects the dots
- `points`: add points to a plot
- `text`: add text labels to a plot using specified x, y coordinates
- `title`: add annotations to x, y axis labels, title, subtitle, outer margin
- `mtext`: add arbitrary text to the margins (inner or outer) of the plot
- `axis`: adding axis ticks/labels
##### With annotations
```{r}
library(datasets)
with(airquality, plot(Wind, Ozone))
title(main = "Ozone and Wind in New York City")  # Add a title
```
a subset of blue points corresponding to the data points in the month of May
```{r}
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City"))
with(subset(airquality, Month == 5), points(Wind, Ozone, col = "blue"))
```

```{r}
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City", type = "n"))
with(subset(airquality, Month == 5), points(Wind, Ozone, col = "blue"))
with(subset(airquality, Month != 5), points(Wind, Ozone, col = "red"))
legend("topright", pch = 1, col = c("blue", "red"), legend = c("May", "Other Months"))
```
`type="n"`: sets up the plot and initializes the graphics device but it doesn't actually plot anything.
###### Annotating functions
- `title()`: include x- and y- axis labels, title, subtitle, and outer margin.
- `mtext()`: adds arbitrary text to either the outer or inner margins of the plot
- `axis()`: adds axis ticks and labels
- `legend()`: explains to the reader what the symbols your plot uses mean.
##### With regression line
```{r}
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City", pch = 20))
model <- lm(Ozone ~ Wind, airquality)
abline(model, lwd = 2)
```
##### Multiple plots
```{r}
par(mfrow = c(1, 2))
with(airquality, {
	plot(Wind, Ozone, main = "Ozone and Wind")
	plot(Solar.R, Ozone, main = "Ozone and Solar Radiation")
})
```

```{r}
par(mfrow = c(1, 3), mar = c(4, 4, 2, 1), oma = c(0, 0, 2, 0))
with(airquality, {
	plot(Wind, Ozone, main = "Ozone and Wind")
	plot(Solar.R, Ozone, main = "Ozone and Solar Radiation")
	plot(Temp, Ozone, main = "Ozone and Temperature")
	mtext("Ozone and Weather in New York City", outer = TRUE)
})
```
#### 3.2.1.3 Create plots and send it to file device
1. Explicitly launch a graphics device
2. Call a plotting function to make a plot (Note: if you are using a file device, no plot will appear on the screen)
3. Annotate plot if necessary
4. Explicitly close graphics device with dev.off() (this is very important!)
```{r}
pdf(file = "myplot.pdf")  ## Open PDF device; create 'myplot.pdf' in my working directory
## Create plot and send to a file (no plot appears on screen)
with(faithful, plot(eruptions, waiting))  
title(main = "Old Faithful Geyser data")  ## Annotate plot; still nothing on screen
dev.off()  ## Close the PDF file device
## Now you can view the file 'myplot.pdf' on your computer
```
#### 3.2.1.4 Open Multiple Graphics Devices
It is possible to open multiple graphics devices (screen, file, or both), for example when viewing multiple plots at once. Plotting can only occur on one graphics device at a time. The currently active graphics device can be found by calling `dev.cur()`. Every open graphics device is assigned an integer >= 2. You can change the active graphics device with `dev.set(<integer>)` where `<integer>` is the number associated with the graphics device you want to switch to.
#### 3.2.1.5 Copy Plots
Copying a plot to another device can be useful because some plots require a lot of code and it can be a pain to type all that in again for a different device.  
`dev.copy`: copy a plot from one device to another  
`dev.copy2pdf`: specifically copy a plot to a PDF file  
NOTE: Copying a plot is not an exact operation, so the result may not be identical to the original.
```{r}
library(datasets)
with(faithful, plot(eruptions, waiting))  ## Create plot on screen device
title(main = "Old Faithful Geyser data")  ## Add a main title
dev.copy(png, file = "geyserplot.png")  ## Copy my plot to a PNG file
dev.off()  ## Don't forget to close the PNG device!
```
#### 3.2.1.6 Colors
- `colors()`: lists the names of 657 predefined colors you can use in any plotting function.
- `colorRamp()`: takes a palette of colors (the arguments) and returns a function that takes values between 0 and 1 as arguments. The 0 and 1 correspond to the extremes of the color palette. Arguments between 0 and 1 return blends of these extremes.
```{r}
pal <- colorRamp(c("red","blue"))
pal(0)
pal(seq(0,1,len=6))
```
- `colorRampPalette()`: takes a palette of colors and returns a function. This function takes integer arguments (instead of numbers between 0 and 1) and returns a vector of colors each of which is a blend of colors of the original palette. The argument you pass to the returned function specifies the number of colors you want returned.
```{r}
p1 <- colorRampPalette(c("red","blue"))
p1(2)
p3 <- colorRampPalette(c("blue","green"),alpha=T)
```
- `smoothScatter()`: creates a 2D histogram of the points in your plot using a certain set of colors. The default set of colors is the blues palette in the RColorBrewer package.
```{r}
smoothScatter(x,y)
```
#### 3.2.1.7 Summary
- Vector formats (pdf,svg) are good for line drawings and plots with solid colors using a modest number of points
  - pdf: useful for line-type graphics and papers. Resizes well, portable, not efficient if a plot has many objects/points.
  - svg: XML-based, scalable vector graphics. Supports animation and interactivity and is useful for web-based plots.
- Bitmap formats (png,jpeg,tiff,bmp) are good for plots with a large number of points, natural scenes or web-based plots
  - png (Portable Network Graphics): good for line drawings or images with solid colors. Uses lossless compression (like the old GIF format), most web browsers can read this format natively. Is good for plots with many points, but does not resize well.
  - jpeg: good for photographs or natural scenes. Use lossy compression, so good for plots with many points. Don't resize well, but can be read by almost any computer and any web browser. Not great for line drawings.

### 3.2.2 {lattice}
lattice plots are created with a single function call such as `xyplot()` or `bwplot()`. is most useful for conditioning types of plots which display how y changes with x across levels of z. The variable z might be a categorical variable of your data. Also good for putting many plots on a screen at once.
#### 3.2.2.1 Plotting Functions
- `xyplot`: main function for creating scatterplots
- `bwplot`: box-and-whiskers plots ("boxplots")
- `histogram`: histograms
- `stripplot`: like a boxplot but with actual points
- `dotplot`: plot dots on "violin strings"
- `splom`: scatterplot matrix; like pairs in base plotting system
- `levelplot`, `contourplot`: for plotting "image" data
```{r}
xyplot(y ~ x | f * g, data)
xyplot(Life.Exp ~ Income | region, data = state, layout = c(4,1))
xyplot(price~carat|color*cut,data=diamonds,strip = FALSE, pch=20, xlab = myxlab,ylab = myylab,main=mymain)
```
colors defining the columns of the plot; `strip` labels each panel
#### 3.2.2.2 Panel Functions
```{r}
xyplot(y ~ x | f, panel = function(x, y, ...) {
       panel.xyplot(x, y, ...)  ## First call the default panel function for 'xyplot'
       panel.abline(h = median(y), lty = 2)  ## Add a horizontal line at the median
       panel.lmline(x, y, col = 2)  ## Overlay a simple linear regression line
})
```
### 3.2.3 {ggplot2}
#### Axis Limits
`ylim()` subsets the data, to include the values that are between minus 3 and 3. The outlier is not included in this data set and so you won't see that data point in this plot. 
```{r}
g + geom_line() + ylim(-3, 3)
```
`coord_cartesian()` the outlier is included in the dataset.
```{r}
g + geom_line() + coord_cartesian(ylim = c(-3, 3))
```
### 3.2.4 {RColorBrewer}
contains interesting and useful color palettes, of which there are 3 types, sequential, divergent, and qualitative.
```{r}
cols <- brewer.pal(3,"BuGn")
```
- `"BuGn"`: palette name
- `3`: how many different colors we want
The colorRamp and colorRampPalette functions can be used in conjunction with color palettes to connect data to colors.
```{r}
pal <- colorRampPalette(cols)
image(volcano,col=pal(20))
```
## 3.3 Clustering / Reduce complexity
### 3.3.1 Hierarchical clustering
#### {base}
Make distance matrix
```{r}
dataFrame <- data.frame(x=x,y=y)
dist(dataFrame)
```
- `method=`: "euclidean" (default), "manhattan", etc.
The dendrogram:
```{r}
hc <- hclust(distxy)
```

## 3.2 Model
simple linear model
```{r}
sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
```
## 3. Further resources
- [R Graph Gallery](https://www.r-graph-gallery.com/)
- [R Bloggers](https://www.r-bloggers.com/)








## Data resources
### Open Government Sites
* United Nations [http://data.un.org/](http://data.un.org/)
* U.S. [http://www.data.gov/](http://www.data.gov/)
  * [List of cities/states with open data](http://simplystatistics.org/2012/01/02/list-of-cities-states-with-open-data-help-me-find/)
* United Kingdom [http://data.gov.uk/](http://data.gov.uk/)
* France [http://www.data.gouv.fr/](http://www.data.gouv.fr/)
* Ghana [http://data.gov.gh/](http://data.gov.gh/)
* Australia [http://data.gov.au/](http://data.gov.au/)
* Germany [https://www.govdata.de/](https://www.govdata.de/) 
* Hong Kong [http://www.gov.hk/en/theme/psi/datasets/](http://www.gov.hk/en/theme/psi/datasets/)
* Japan [http://www.data.go.jp/](http://www.data.go.jp/)
* Many more [http://www.data.gov/opendatasites](http://www.data.gov/opendatasites)

### Gapminder
Gapminder has a lot of data about development in particular in human heath.
[http://www.gapminder.org/](http://www.gapminder.org/)
### Survey data from the United States
[http://www.asdfree.com/](http://www.asdfree.com/)
### Infochimps Marketplace
The Infochimps Marketplace has a bunch of different data sets which you can sort by various different tags.
[http://www.infochimps.com/marketplace](http://www.infochimps.com/marketplace)
### Kaggle
Kaggle is a company that offers data science competitions, and they often have very interesting data sets that they make available as part of those competitions. So they're good for practice, but they're also good for potentially discovering new, interesting things that can help companies solve real problems.
[http://www.kaggle.com/](http://www.kaggle.com/)
### Collections by data scientists
* Hilary Mason http://bitly.com/bundles/hmason/1
* Peter Skomoroch https://delicious.com/pskomoroch/dataset
* Jeff Hammerbacher http://www.quora.com/Jeff-Hammerbacher/Introduction-to-Data-Science-Data-Sets
* Gregory Piatetsky-Shapiro http://www.kdnuggets.com/gps.html
* [http://blog.mortardata.com/post/67652898761/6-dataset-lists-curated-by-data-scientists](http://blog.mortardata.com/post/67652898761/6-dataset-lists-curated-by-data-scientists)

### More specialized collections
* [Stanford Large Network Data](http://snap.stanford.edu/data/) focuses on network data, machine learning
* [UCI Machine Learning](http://archive.ics.uci.edu/ml/) has a variety of data sets that can be used to practice your classification or predictions
* [KDD Nugets Datasets](http://www.kdnuggets.com/datasets/index.html)
* [CMU Statlib](http://lib.stat.cmu.edu/datasets/) one of the most famous canonical sets of data sets
* [Gene expression omnibus](http://www.ncbi.nlm.nih.gov/geo/) focuses on data sets that come from human genomic experiments or other organismal genomics experiments
* [ArXiv Data](http://arxiv.org/help/bulk_data)
* [Public Data Sets on Amazon Web Services](http://aws.amazon.com/publicdatasets/)

### Some API's with R interfaces
* [twitter](https://dev.twitter.com/) and [twitteR](http://cran.r-project.org/web/packages/twitteR/index.html) package
* [figshare](http://api.figshare.com/docs/intro.html) and [rfigshare](http://cran.r-project.org/web/packages/rfigshare/index.html)
* [PLoS](http://api.plos.org/) and [rplos](http://cran.r-project.org/web/packages/rplos/rplos.pdf)
* [rOpenSci](http://ropensci.org/packages/index.html)
* [Facebook](https://developers.facebook.com/) and [RFacebook](http://cran.r-project.org/web/packages/Rfacebook/)
* [Google maps](https://developers.google.com/maps/) and [RGoogleMaps](http://cran.r-project.org/web/packages/RgoogleMaps/index.html)